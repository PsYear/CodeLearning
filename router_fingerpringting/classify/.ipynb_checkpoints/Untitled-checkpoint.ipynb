{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf.........\n",
      "Logistic\n",
      "train_valid_acc: 0.428151054438\n",
      "test_valid_acc: 0.405286343612\n",
      "Naive Bayes\n",
      "train_valid_acc: 0.344286414909\n",
      "test_valid_acc: 0.328193832599\n",
      "Support Vector Classification\n",
      "train_valid_acc: 0.417116233448\n",
      "test_valid_acc: 0.394273127753\n",
      "Random Forest\n",
      "train_valid_acc: 1.0\n",
      "test_valid_acc: 0.649779735683\n",
      "XJTUWlan/ar\n",
      "XJTUWlan/ar\n",
      "xiaomi/arp_\n",
      "xiaomi/arp_\n",
      "xiaomi/arp_\n",
      "*****************\n",
      "Logistic\n",
      "train_valid_acc: 0.778481012658\n",
      "test_valid_acc: 0.75\n",
      "Naive Bayes\n",
      "train_valid_acc: 0.756329113924\n",
      "test_valid_acc: 0.861111111111\n",
      "Support Vector Classification\n",
      "train_valid_acc: 0.810126582278\n",
      "test_valid_acc: 0.777777777778\n",
      "Random Forest\n",
      "train_valid_acc: 1.0\n",
      "test_valid_acc: 0.944444444444\n",
      "*****************\n",
      "xunjie/arp_\n",
      "xunjie/arp_\n",
      "xiaomi/arp_\n",
      "xiaomi/arp_\n",
      "xiaomi/arp_\n",
      "*****************\n",
      "Logistic\n",
      "train_valid_acc: 0.686153846154\n",
      "test_valid_acc: 0.567567567568\n",
      "Naive Bayes\n",
      "train_valid_acc: 0.627692307692\n",
      "test_valid_acc: 0.648648648649\n",
      "Support Vector Classification\n",
      "train_valid_acc: 0.701538461538\n",
      "test_valid_acc: 0.675675675676\n",
      "Random Forest\n",
      "train_valid_acc: 1.0\n",
      "test_valid_acc: 0.756756756757\n",
      "*****************\n",
      "tplink_4f10\n",
      "xiaomi/arp_\n",
      "xiaomi/arp_\n",
      "xiaomi/arp_\n",
      "*****************\n",
      "Logistic\n",
      "train_valid_acc: 0.878892733564\n",
      "test_valid_acc: 0.939393939394\n",
      "Naive Bayes\n",
      "train_valid_acc: 0.737024221453\n",
      "test_valid_acc: 0.757575757576\n",
      "Support Vector Classification\n",
      "train_valid_acc: 0.906574394464\n",
      "test_valid_acc: 0.818181818182\n",
      "Random Forest\n",
      "train_valid_acc: 1.0\n",
      "test_valid_acc: 0.878787878788\n",
      "*****************\n",
      "tplink_fe1c\n",
      "xiaomi/arp_\n",
      "xiaomi/arp_\n",
      "xiaomi/arp_\n",
      "*****************\n",
      "Logistic\n",
      "train_valid_acc: 0.725433526012\n",
      "test_valid_acc: 0.75\n",
      "Naive Bayes\n",
      "train_valid_acc: 0.745664739884\n",
      "test_valid_acc: 0.85\n",
      "Support Vector Classification\n",
      "train_valid_acc: 0.78323699422\n",
      "test_valid_acc: 0.8\n",
      "Random Forest\n",
      "train_valid_acc: 1.0\n",
      "test_valid_acc: 0.825\n",
      "*****************\n",
      "xunjie/arp_\n",
      "xunjie/arp_\n",
      "XJTUWlan/ar\n",
      "XJTUWlan/ar\n",
      "*****************\n",
      "Logistic\n",
      "train_valid_acc: 0.743670886076\n",
      "test_valid_acc: 0.555555555556\n",
      "Naive Bayes\n",
      "train_valid_acc: 0.699367088608\n",
      "test_valid_acc: 0.555555555556\n",
      "Support Vector Classification\n",
      "train_valid_acc: 0.756329113924\n",
      "test_valid_acc: 0.638888888889\n",
      "Random Forest\n",
      "train_valid_acc: 1.0\n",
      "test_valid_acc: 0.694444444444\n",
      "*****************\n",
      "tplink_4f10\n",
      "XJTUWlan/ar\n",
      "XJTUWlan/ar\n",
      "*****************\n",
      "Logistic\n",
      "train_valid_acc: 0.813148788927\n",
      "test_valid_acc: 0.757575757576\n",
      "Naive Bayes\n",
      "train_valid_acc: 0.681660899654\n",
      "test_valid_acc: 0.636363636364\n",
      "Support Vector Classification\n",
      "train_valid_acc: 0.833910034602\n",
      "test_valid_acc: 0.69696969697\n",
      "Random Forest\n",
      "train_valid_acc: 1.0\n",
      "test_valid_acc: 0.787878787879\n",
      "*****************\n",
      "tplink_fe1c\n",
      "XJTUWlan/ar\n",
      "XJTUWlan/ar\n",
      "*****************\n",
      "Logistic\n",
      "train_valid_acc: 0.895569620253\n",
      "test_valid_acc: 0.861111111111\n",
      "Naive Bayes\n",
      "train_valid_acc: 0.943037974684\n",
      "test_valid_acc: 0.916666666667\n",
      "Support Vector Classification\n",
      "train_valid_acc: 0.946202531646\n",
      "test_valid_acc: 0.861111111111\n",
      "Random Forest\n",
      "train_valid_acc: 1.0\n",
      "test_valid_acc: 0.972222222222\n",
      "*****************\n",
      "tplink_4f10\n",
      "xunjie/arp_\n",
      "xunjie/arp_\n",
      "*****************\n",
      "Logistic\n",
      "train_valid_acc: 0.875432525952\n",
      "test_valid_acc: 0.848484848485\n",
      "Naive Bayes\n",
      "train_valid_acc: 0.806228373702\n",
      "test_valid_acc: 0.787878787879\n",
      "Support Vector Classification\n",
      "train_valid_acc: 0.916955017301\n",
      "test_valid_acc: 0.878787878788\n",
      "Random Forest\n",
      "train_valid_acc: 1.0\n",
      "test_valid_acc: 0.848484848485\n",
      "*****************\n",
      "tplink_fe1c\n",
      "xunjie/arp_\n",
      "xunjie/arp_\n",
      "*****************\n",
      "Logistic\n",
      "train_valid_acc: 0.812307692308\n",
      "test_valid_acc: 0.72972972973\n",
      "Naive Bayes\n",
      "train_valid_acc: 0.84\n",
      "test_valid_acc: 0.756756756757\n",
      "Support Vector Classification\n",
      "train_valid_acc: 0.873846153846\n",
      "test_valid_acc: 0.702702702703\n",
      "Random Forest\n",
      "train_valid_acc: 1.0\n",
      "test_valid_acc: 0.72972972973\n",
      "*****************\n",
      "tplink_fe1c\n",
      "tplink_4f10\n",
      "*****************\n",
      "Logistic\n",
      "train_valid_acc: 0.9723183391\n",
      "test_valid_acc: 0.939393939394\n",
      "Naive Bayes\n",
      "train_valid_acc: 0.982698961938\n",
      "test_valid_acc: 0.939393939394\n",
      "Support Vector Classification\n",
      "train_valid_acc: 0.982698961938\n",
      "test_valid_acc: 0.969696969697\n",
      "Random Forest\n",
      "train_valid_acc: 1.0\n",
      "test_valid_acc: 0.939393939394\n",
      "*****************\n"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, \n",
    "                                  Lasso, RandomizedLasso)\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from minepy import MINE\n",
    "import sys,re,os\n",
    "import numpy as np\n",
    "from scipy import stats \n",
    "import matplotlib.pylab as plt\n",
    "import random\n",
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib import pyplot\n",
    "import random\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from decimal import getcontext, Decimal \n",
    "\n",
    "\n",
    "\n",
    "win_path = \"F:\\github_workspace\\CodeLearning\\\\router_fingerpringting\\classify\\\\\"\n",
    "ubuntu_path = \"/home/wendell/Documents/github/CodeLearning/router_fingerpringting/classify/\"\n",
    "win2_path = \"C:\\Users\\peter\\Documents\\\\github_new\\\\CodeLearning\\\\router_fingerpringting\\\\classify\\\\\"\n",
    "\n",
    "\n",
    "filepath_arp_set_before = [\n",
    "\"xiaomi/arp_data.txt\",\n",
    "\"xiaomi/arp_data_1.txt\",\n",
    "\"xiaomi/arp_data_2.txt\",\n",
    "\"XJTUWlan/arp_data.txt\",\n",
    "\"XJTUWlan/arp_data_1.txt\",\n",
    "\"xunjie/arp_data.txt\",\n",
    "\"xunjie/arp_data_1.txt\",\n",
    "\"tplink_4f10/arp_data_1.txt\",\n",
    "\"tplink_fe1c1a/arp_data_1.txt\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "filepath_icmp_set = [\n",
    "\"/home/wendell/Documents/github/CodeLearning/router_fingerpringting/classify/xiaomi/icmp_data.txt\",\n",
    "\"/home/wendell/Documents/github/CodeLearning/router_fingerpringting/classify/xiaomi/icmp_data_1.txt\",\n",
    "\"/home/wendell/Documents/github/CodeLearning/router_fingerpringting/classify/xunjie/icmp_data.txt\",\n",
    "\"/home/wendell/Documents/github/CodeLearning/router_fingerpringting/classify/xunjie/icmp_data_1.txt\",\n",
    "\"/home/wendell/Documents/github/CodeLearning/router_fingerpringting/classify/XJTUWlan/icmp_data_1.txt\",\n",
    "\"/home/wendell/Documents/github/CodeLearning/router_fingerpringting/classify/tplink_4f10/icmp_data_1.txt\",\n",
    "\"/home/wendell/Documents/github/CodeLearning/router_fingerpringting/classify/tplink_4f10/icmp_data_2.txt\",\n",
    "\"/home/wendell/Documents/github/CodeLearning/router_fingerpringting/classify/tplink_fe1c1a/icmp_data_1.txt\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "filepath_icmp_set_before = [\n",
    "\"xiaomi/icmp_data.txt\",\n",
    "\"xiaomi/icmp_data_1.txt\",\n",
    "\"xunjie/icmp_data.txt\",\n",
    "\"xunjie/icmp_data_1.txt\",\n",
    "\"XJTUWlan/icmp_data_1.txt\",\n",
    "\"tplink_4f10/icmp_data_1.txt\",\n",
    "\"tplink_4f10/icmp_data_2.txt\",\n",
    "\"tplink_fe1c1a/icmp_data_1.txt\"\n",
    "]\n",
    "\n",
    "def filepath_after(os, file):\n",
    "\tfile_ppath = []\n",
    "\tfor i in file:\n",
    "\t\tfile_ppath.append(os+i)\n",
    "\treturn file_ppath\n",
    "\n",
    "\n",
    "\n",
    "filepath_arp_set = filepath_after(win2_path, filepath_arp_set_before)\n",
    "filepath_icmp_set = filepath_after(win2_path, filepath_icmp_set_before)\n",
    "# filepath_arp_set = filepath_after(win_path, filepath_arp_set_before)\n",
    "# filepath_icmp_set = filepath_after(win_path, filepath_icmp_set_before)\n",
    "\n",
    "label_str = []\n",
    "\n",
    "\n",
    "def abs(num):\n",
    "\tif num >= 0:\n",
    "\t\treturn num\n",
    "\telse:\n",
    "\t\treturn -num\n",
    "\n",
    "\n",
    "def changetime(str_time):\n",
    "\tdec = str_time.split(\":\")\n",
    "\ttime = int(dec[0])*3600+int(dec[1])*60\n",
    "\tsec = dec[2].split(\".\")\n",
    "\ttime = time + int(sec[0])+int(sec[1])*1e-6\n",
    "\treturn float(time)\n",
    "\n",
    "\n",
    "def draw_sort(grade):\n",
    "\tglobal label_str\n",
    "\tfor i in range(len(grade)):\n",
    "\t\tplt.plot(grade[i],label=label_str[i])\n",
    "\t\t# plt.plot(ind, gkde[i](ind), label=label_str[i])\n",
    "\tplt.title('Kernel Density Estimation')\n",
    "\tplt.legend()\n",
    "\tplt.show()\n",
    "\n",
    "def readfile_sort(filepath):\n",
    "\tdata_list = open(filepath,'r').readlines()\n",
    "\tdata_time_IAT_list = []\n",
    "\tdata_time_delta_list = []\n",
    "\tdata_time_clock_list = []\n",
    "\tdata_time_test_list = []\n",
    "\tfor i in data_list:\n",
    "\t\tif len(i) != 1:\n",
    "\t\t\tdata_time =[changetime(x) for x in i.split(\" \")[:-1]]\n",
    "\t\t\tdata_time_IAT = [data_time[num+2] - data_time[num] for num in range(1,len(data_time)-2,2)]\n",
    "\t\t\tdata_time_delta = [data_time[num+1] - data_time[num] for num in range(0,len(data_time),2)]\n",
    "\t\t\tdata_time_clock = [(data_time[num+3] - data_time[num+1])/(data_time[num+2] - data_time[num]) for num in range(0,len(data_time)-2,2)]\n",
    "\t\t\tdata_time_test = [(data_time[num+3]-data_time[num+1])-(data_time[num+2]-data_time[num+0]) for num in range(0, len(data_time)-2,2)]\n",
    "\t\t\tdata_time_delta_list += data_time_delta\n",
    "\t\t\tdata_time_IAT_list += data_time_IAT\n",
    "\t\t\tdata_time_clock_list += data_time_clock\n",
    "\t\t\tdata_time_test_list += data_time_test\n",
    "\tdata_time_delta_list.sort()\n",
    "\tdata_time_test_list.sort()\n",
    "\tdata_time_IAT_list.sort()\n",
    "\tdata_time_clock.sort()\n",
    "\treturn [data_time_delta_list,data_time_IAT_list, data_time_clock,data_time_test_list]\n",
    "\n",
    "def readfile_sort_set(filepath):\n",
    "\t'''\n",
    "\twin2 is 81:90\n",
    "\t'''\n",
    "\tnum_fo = 81\n",
    "\tnum_be = 90\n",
    "\tdata_time_IAT_list = []\n",
    "\tdata_time_delta_list = []\n",
    "\tdata_time_clock_list = []\n",
    "\tdata_time_test_list = []\n",
    "\tflag = 0\n",
    "\tglobal label_str\n",
    "\tlabel_str.append(filepath[0][num_fo:num_be])\n",
    "\tfor i in range(len(filepath)):\n",
    "\t\tif i != 0:\n",
    "\t\t\tname =  filepath[i][num_fo:num_be]\n",
    "\t\t\tname_pre = filepath[i-1][num_fo:num_be]\n",
    "\t\t\tif name == name_pre:\n",
    "\t\t\t\tflag = 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tlabel_str.append(name)\n",
    "\t\t\t\tflag = 0\n",
    "\t\ti = filepath[i]\n",
    "\t\tif flag == 1:\n",
    "\t\t\t\n",
    "\t\t\tdata_time_delta_list[-1]+=readfile_sort(i)[0]\n",
    "\t\t\tdata_time_IAT_list[-1]+=readfile_sort(i)[1]\n",
    "\t\t\tdata_time_clock_list[-1]+=readfile_sort(i)[2]\n",
    "\t\t\tdata_time_test_list[-1]+=readfile_sort(i)[3]\n",
    "\t\telse:\n",
    "\t\t\tdata_time_delta_list.append(readfile_sort(i)[0])\n",
    "\t\t\tdata_time_IAT_list.append(readfile_sort(i)[1])\n",
    "\t\t\tdata_time_clock_list.append(readfile_sort(i)[2])\n",
    "\t\t\tdata_time_test_list.append(readfile_sort(i)[3])\n",
    "\treturn [data_time_delta_list,data_time_IAT_list,data_time_clock_list,data_time_test_list]\n",
    "\n",
    "def readfile(filepath):\n",
    "\tdata_list = open(filepath,'r').readlines()\n",
    "\tdata_time_IAT_list = []\n",
    "\tdata_time_delta_list = []\n",
    "\tdata_time_clock_list = []\n",
    "\tdata_time_test_list = []\n",
    "\tfor i in data_list:\n",
    "\t\tif len(i) != 1:\n",
    "\t\t\tdata_time =[changetime(x) for x in i.split(\" \")[:-1]]\n",
    "\t\t\tdata_time_IAT = [data_time[num+2] - data_time[num] for num in range(1,len(data_time)-2,2)]\n",
    "\t\t\tdata_time_delta = [data_time[num+1] - data_time[num] for num in range(0,len(data_time),2)]\n",
    "\t\t\tdata_time_clock = [((data_time[num+3] - data_time[num+1])/(data_time[num+2] - data_time[num])) for num in range(0,len(data_time)-2,2)]\n",
    "\t\t\tdata_time_test = [(data_time[num+3]-data_time[num+1])-(data_time[num+2]-data_time[num+0]) for num in range(0, len(data_time)-2,2)]\n",
    "\t\t\tdata_time_delta_list += data_time_delta\n",
    "\t\t\tdata_time_IAT_list += data_time_IAT\n",
    "\t\t\tdata_time_clock_list += data_time_clock\n",
    "\t\t\tdata_time_test_list += data_time_test\n",
    "\treturn [data_time_delta_list,data_time_IAT_list, data_time_clock_list,data_time_test_list]\n",
    "\n",
    "\n",
    "\n",
    "def readfile_set(filepath):\n",
    "\tdata_time_IAT_list = []\n",
    "\tdata_time_delta_list = []\n",
    "\tdata_time_clock_list = []\n",
    "\tdata_time_test_list = []\n",
    "\tflag = 0\n",
    "\t'''\n",
    "\twin2 is 81:90\n",
    "\t'''\n",
    "\tnum_fo = 81\n",
    "\tnum_be = 90\n",
    "\n",
    "\tglobal label_str\n",
    "\tlabel_str.append(filepath[0][num_fo:num_be])\n",
    "\tfor i in range(len(filepath)):\n",
    "\t\tif i != 0:\n",
    "\t\t\tname =  filepath[i][num_fo:num_be]\n",
    "\t\t\tname_pre = filepath[i-1][num_fo:num_be]\n",
    "\t\t\tif name == name_pre:\n",
    "\t\t\t\tflag = 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tlabel_str.append(name)\n",
    "\t\t\t\tflag = 0\n",
    "\t\ti = filepath[i]\n",
    "\t\tif flag == 1:\n",
    "\t\t\trf = readfile(i)\n",
    "\t\t\tdata_time_delta_list[-1]+rf[0]\n",
    "\t\t\tdata_time_IAT_list[-1]+rf[1]\n",
    "\t\t\tdata_time_clock_list[-1]+rf[2]\n",
    "\t\t\tdata_time_test_list[-1]+rf[3]\n",
    "\t\telse:\n",
    "\t\t\trf = readfile(i)\n",
    "\t\t\tdata_time_delta_list.append(rf[0])\n",
    "\t\t\tdata_time_IAT_list.append(rf[1])\n",
    "\t\t\tdata_time_clock_list.append(rf[2])\n",
    "\t\t\tdata_time_test_list.append(rf[3])\n",
    "\n",
    "\treturn [data_time_delta_list,data_time_IAT_list,data_time_clock_list,data_time_test_list]\n",
    "\n",
    "\n",
    "def draw_kde_arp_single(grade):\n",
    "\tglobal label_str\n",
    "\tgkde=[]\n",
    "\tind = np.arange(0.,0.5,0.001)\n",
    "\tfor i in range(len(grade)):\n",
    "\t\tgkde.append(stats.kde.gaussian_kde(grade[i]))\n",
    "\t\tplt.plot(ind, gkde[i](ind),label=label_str[i])\n",
    "\t\t# plt.plot(ind, gkde[i](ind), label=label_str[i])\n",
    "\tplt.title('Kernel Density Estimation')\n",
    "\tplt.legend()\n",
    "\tplt.show()\n",
    "\n",
    "def draw_kde_icmp_single(grade):\n",
    "\tglobal label_str\n",
    "\tgkde=[]\n",
    "\tind = np.arange(0.,3,0.001)\n",
    "\tfor i in range(len(grade)):\n",
    "\t\tgkde.append(stats.kde.gaussian_kde(grade[i]))\n",
    "\t\tplt.plot(ind, gkde[i](ind),label=label_str[i])\n",
    "\t\t# plt.plot(ind, gkde[i](ind), label=label_str[i])\n",
    "\tplt.title('Kernel Density Estimation')\n",
    "\tplt.legend()\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def draw_single(grade):\n",
    "\tfor i in range(len(grade)):\n",
    "\t\tplt.plot(grade[i],label=label_str[i])\n",
    "\t\t# plt.plot(ind, gkde[i](ind), label=label_str[i])\n",
    "\tplt.title('Kernel Density Estimation')\n",
    "\tplt.legend()\n",
    "\tplt.show()\n",
    "\n",
    "def draw_div(grade):\n",
    "\tco = ['b','k','g','c','m','y','r','w']\n",
    "\tfor j in range(len(grade[0])):\n",
    "\t\tfor i in range(min(len(grade[0][j]),len(grade[1][j]))):\n",
    "\t\t\tplt.plot(grade[0][j][i],grade[1][j][i],'+',color = co[j])\n",
    "\tplt.title('Kernel Density Estimation')\n",
    "\tplt.legend()\n",
    "\tplt.show()\n",
    "\n",
    "def learning_feature(feature,inum =1):\n",
    "\tmin_len = 99999999\n",
    "\tfor i in feature:\n",
    "\t\tfor j in i :\n",
    "\t\t\tif len(j) < min_len:\n",
    "\t\t\t\tmin_len = len(j)\n",
    "\tnew_set = []\n",
    "\tnew_fe = []\n",
    "\tmin_len = min_len -inum+1 # inum is times of the feature_num\n",
    "\tsample_num = len(feature[0])\n",
    "\tfor sample in range(sample_num):\n",
    "\t\tone_set = []\n",
    "\t\tfor num in range(0,min_len,inum):\n",
    "\t\t\tone_sample = []\n",
    "\t\t\tfor feature_num in feature:\n",
    "\t\t\t\tfor i in range(inum):\n",
    "\t\t\t\t\tone_sample.append(feature_num[sample][num+i])\n",
    "\t\t\tone_set.append(one_sample)\n",
    "\t\t\tnew_fe.append(one_sample)\n",
    "\t\tnew_set.append(one_set)\n",
    "\tnew_set = np.array(new_set)\n",
    "\treturn new_set,new_fe\n",
    "\n",
    "\n",
    "def learning_feature_sliding(feature,inum =1):\n",
    "\tmin_len = 99999999\n",
    "\tfor i in feature:\n",
    "\t\tfor j in i :\n",
    "\t\t\tif len(j) < min_len:\n",
    "\t\t\t\tmin_len = len(j)\n",
    "\tnew_set = []\n",
    "\tnew_fe = []\n",
    "\tmin_len = min_len -inum+1 # inum is times of the feature_num\n",
    "\tsample_num = len(feature[0])\n",
    "\tfor sample in range(sample_num):\n",
    "\t\tone_set = []\n",
    "\t\tfor num in range(0,min_len,inum):\n",
    "\t\t\tone_sample = []\n",
    "\t\t\tfor feature_num in feature:\n",
    "\t\t\t\tfor i in range(inum):\n",
    "\t\t\t\t\tone_sample.append(feature_num[sample][num+i])\n",
    "\t\t\tone_set.append(one_sample)\n",
    "\t\t\tnew_fe.append(one_sample)\n",
    "\t\tnew_set.append(one_set)\n",
    "\tnew_set = np.array(new_set)\n",
    "\treturn new_set,new_fe\n",
    "\n",
    "def random_re(p,p_l):\n",
    "\tpp = []\n",
    "\tpp_l = []\n",
    "\tlen_num = len(p)\n",
    "\tfor i in range(len_num):\n",
    "\t\tnum = random.randint(0,len_num-i-1)\n",
    "\t\tpp.append(p.pop(num))\n",
    "\t\tpp_l.append(p_l.pop(num))\n",
    "\treturn pp,pp_l\n",
    "\n",
    "def learning_label(new_set):\n",
    "\tlabel_all = []\n",
    "\tfor i in range(len(new_set)):\n",
    "\t\tlabel = [i for num in range(len(new_set[0]))]\n",
    "\t\tlabel_all = label_all+label\n",
    "\treturn  label_all\n",
    "\n",
    "\n",
    "def pre_fe_la(filepath_icmp_set,filepath_arp_set,num=1):\n",
    "\treshape_file_set = []\n",
    "\ticmp_set = readfile_set(filepath_icmp_set)\n",
    "\tarp_set = readfile_set(filepath_arp_set)\n",
    "\tfor i in range(4):   # 4 feature number\n",
    "\t\treshape_file_set.append(icmp_set[i])\n",
    "\t\treshape_file_set.append(arp_set[i])\n",
    "\tp,pp = learning_feature(reshape_file_set,num)\n",
    "\tp_l = learning_label(p)\n",
    "\treturn random_re(pp,p_l)\n",
    "\n",
    "\n",
    "\n",
    "def RF(X,y):\n",
    "\tlen_x = len(X)\n",
    "\ttrain = int(0.8 * len_x)\n",
    "\tvalid = int(0.1 *len_x)\n",
    "\ttrain_valid = train + valid\n",
    "\n",
    "\tX_train, y_train = X[:train], y[:train]\n",
    "\tX_valid, y_valid = X[train:train_valid], y[train:train_valid]\n",
    "\tX_train_valid, y_train_valid = X[:train_valid], y[:train_valid]\n",
    "\tX_test, y_test = X[train_valid:], y[train_valid:]\n",
    "\n",
    "\trfc = RandomForestClassifier(n_estimators=100)\n",
    "\tlr = LogisticRegression()\n",
    "\tgnb = GaussianNB()\n",
    "\tsvc = LinearSVC(C=1.0)\n",
    "\tfor clf, name in [(lr, 'Logistic'),\n",
    "\t                  (gnb, 'Naive Bayes'),\n",
    "\t                  (svc, 'Support Vector Classification'),\n",
    "\t                  (rfc, 'Random Forest')]:\n",
    "\t\t\n",
    "\n",
    "\t\t# clf.fit(X_train, y_train)\n",
    "\t\t# print name\n",
    "\t\t# print \"train_valid_acc:\",clf.score(X_train_valid, y_train_valid)\n",
    "\t\t# print \"test_acc:\",clf.score(X_test,y_test)\n",
    "\t# return rfc.score(X_train_valid, y_train_valid),rfc.score(X_test,y_test)\n",
    "\n",
    "\n",
    "\t\tprint name\n",
    "\t\tclf.fit(X_train_valid, y_train_valid)\n",
    "\t\t# clf_probs = clf.predict_proba(X_test)\n",
    "\t\t# score = log_loss(y_test, clf_probs)\n",
    "\t\tprint  \"train_valid_acc:\",clf.score(X_train_valid, y_train_valid)\n",
    "\t\t\n",
    "\t\tprint  \"test_valid_acc:\",clf.score(X_test,y_test)\n",
    "\t\twith open(\"result.txt\",'a') as file:\n",
    "\t\t\tfile.write(str(name)+\"\\n\")\n",
    "\t\t\tfile.write(\"train_valid_acc:\\t\"+str(clf.score(X_train_valid, y_train_valid))+\"\\n\")\n",
    "\t\t\tfile.write(\"test_valid_acc:\\t\"+str(clf.score(X_test,y_test))+\"\\n\")\n",
    "\t\tif(name == \"Random Forest\"):\n",
    "\n",
    "\t\t\tRF_TRAIN = clf.score(X_train_valid, y_train_valid)\n",
    "\t\t\tRF_TEST  = clf.score(X_test,y_test)\n",
    "\treturn RF_TRAIN,RF_TEST\n",
    "\n",
    "\t\n",
    "\n",
    "\n",
    "def change_file_re(filepath_arp_set,filepath_icmp_set):\n",
    "\tdic_num_route = [[[0,1,2],[0,1]],[[3,4],[4]],[[5,6],[2,3]],[[7],[5,6]],[[8],[7]]]\n",
    "\ticmp_set_set = []\n",
    "\tarp_set_set = []\n",
    "\tfor i in range(random.randint(4,4)):\n",
    "\t\tnum = random.randint(0,4-i)\n",
    "\t\tlist_num = dic_num_route.pop(num)\n",
    "\t\tfor ii in list_num[0]:\n",
    "\t\t\tarp_set_set.append(filepath_arp_set[ii])\t\n",
    "\t\tfor jj in list_num[1]:\n",
    "\t\t\ticmp_set_set.append(filepath_icmp_set[jj])\n",
    "\tfilepath_icmp_set = icmp_set_set\n",
    "\tfilepath_arp_set = arp_set_set\n",
    "\treturn filepath_icmp_set,filepath_arp_set\n",
    "\n",
    "\n",
    "def choice_file_re(filepath_arp_set,filepath_icmp_set):\n",
    "\tdic_num_route = [[[0,1,2],[0,1]],[[3,4],[4]],[[5,6],[2,3]],[[7],[5,6]],[[8],[7]]]\n",
    "\tfor i in range(5):\n",
    "\t\tfor j in range(i+1,5):\n",
    "\t\t\ticmp_set_set = []\n",
    "\t\t\tarp_set_set = []\n",
    "\t\t\tlist_num = [dic_num_route[j],dic_num_route[i]]\n",
    "\t\t\tfor k in range(2):\n",
    "\t\t\t\tfor ii in list_num[k][0]:\n",
    "\t\t\t\t\tarp_set_set.append(filepath_arp_set[ii])\n",
    "\t\t\t\t\tprint filepath_arp_set[ii][81:92]\t# 显示路由器型号\n",
    "\t\t\t\tfor jj in list_num[k][1]:\t\n",
    "\t\t\t\t\ticmp_set_set.append(filepath_icmp_set[jj])\n",
    "\t\t\tdata_test = []\n",
    "\t\t\tprint \"*****************\"\n",
    "\t\t\tfor k in range(1):  # the ir of test to get mean  \n",
    "\t\t\t\t# for dd in range(3,10):\n",
    "\t\t\t\t# \tX,Y = pre_fe_la(icmp_set_set,arp_set_set,dd)  #dd 是窗口长度\n",
    "\t\t\t\t# \td1,d2 = RF(X,Y)\n",
    "\t\t\t\t# \tfeature_coff(X,Y) # 训练和测试\n",
    "\n",
    "\t\t\t\tX,Y = pre_fe_la(icmp_set_set,arp_set_set,7)  #5 是窗口长度\n",
    "\t\t\t\td1,d2 = RF(X,Y)\n",
    "\t\t\t\t# feature_coff(X,Y) # 训练和测试\n",
    "\t\t\t\t# X,Y = pre_fe_la(icmp_set_set,arp_set_set,4)\n",
    "\t\t\t\t# d1,d2 = RF(X,Y)\n",
    "\t\t\t\t# feature_coff(X,Y)\n",
    "\t\t\t\t# X,Y = pre_fe_la(icmp_set_set,arp_set_set,3)\n",
    "\t\t\t\t# d1,d2 = RF(X,Y)\n",
    "\t\t\t\t# feature_coff(X,Y)\n",
    "\t\t\tdata_test = np.array(data_test)\n",
    "\t\t\t# print \"train_valid_acc:\",sum(data_test[:,0])/len(data_test[:,0])\n",
    "\t\t\t# print \"test_acc:\",sum(data_test[:,1])/len(data_test[:,1])\n",
    "\t\t\tprint \"*****************\"\n",
    "\n",
    "def rank_to_dict(ranks, names, order=1):\n",
    "    minmax = MinMaxScaler()\n",
    "    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n",
    "    ranks = map(lambda x: round(x, 2), ranks)\n",
    "    return dict(zip(names, ranks ))\n",
    "\n",
    "def decimal2(x):\n",
    "\treturn str(\"%.2f\"%x)\n",
    "\n",
    "\n",
    "\n",
    "def feature_coff(X,Y):\n",
    "\tlen_x_feature = len(X[1])\n",
    "\tprint len_x_feature\n",
    "\tnames = [\"x%s\" % i for i in range(len_x_feature)]\n",
    "\tranks = {}\n",
    "\tlr = LinearRegression(normalize=True)\n",
    "\tlr.fit(X, Y)\n",
    "\tranks[\"Lin\"] = rank_to_dict(np.abs(lr.coef_), names)\n",
    "\n",
    "\tridge = Ridge(alpha=7)\n",
    "\tridge.fit(X, Y)\n",
    "\tranks[\"Ridge\"] = rank_to_dict(np.abs(ridge.coef_), names)\n",
    "\n",
    "\n",
    "\tlasso = Lasso(alpha=.05)\n",
    "\tlasso.fit(X, Y)\n",
    "\tranks[\"Lasso\"] = rank_to_dict(np.abs(lasso.coef_), names)\n",
    "\n",
    "\n",
    "\t#stop the search when 5 features are left (they will get equal scores)\n",
    "\trfe = RFE(lr, n_features_to_select=5)\n",
    "\trfe.fit(X,Y)\n",
    "\tranks[\"RFE\"] = rank_to_dict(map(float, rfe.ranking_), names, order=-1)\n",
    "\n",
    "\trf = RandomForestRegressor()\n",
    "\trf.fit(X,Y)\n",
    "\tranks[\"RF\"] = rank_to_dict(rf.feature_importances_, names)\n",
    "\n",
    "\n",
    "\tf, pval  = f_regression(X, Y, center=True)\n",
    "\t# ranks[\"Corr.\"] = rank_to_dict(f, names)\n",
    "\tranks[\"p_val\"] = rank_to_dict(pval, names)\n",
    "\n",
    "\tranks_no = ranks.copy()\n",
    "\tranks_no.pop(\"p_val\")\n",
    "\tr = {}\n",
    "\tfor name in names:\n",
    "\t    r[name] = round(np.mean([ranks[method][name] \n",
    "\t                             for method in ranks_no.keys()]), 2)\n",
    "\n",
    "\tmethods = sorted(ranks.keys())\n",
    "\tranks[\"Mean\"] = r\n",
    "\tmethods.append(\"Mean\")\n",
    "\t\n",
    "\n",
    "\tprint \"\\t%s\" % \"\\t\".join(methods)\n",
    "\t\n",
    "\n",
    "\tmean_list_count = []\n",
    "\tfor name in names:\n",
    "\t    print \"%s\\t%s\" % (name, \"\\t\".join(map(str, \n",
    "\t                         [ranks[method][name] for method in methods])))\n",
    "\t    mean_list_count.append(ranks['Mean'][name])\n",
    "\n",
    "\twith open(\"feature_select_means\"+str(len_x_feature)+\".txt\",'a') as filename:\n",
    "\t\tfilename.write(\"%s\\n\" %(\"\\t\".join(map(decimal2,mean_list_count))))\n",
    "\n",
    "\twith open(\"feature_select\"+str(len_x_feature)+\".txt\",'a') as filename:\n",
    "\t\tfilename.write(str(len_x_feature))\n",
    "\t\tfilename.write(\"\\n\\t%s\\n\" % \"\\t\\t\".join(methods))\n",
    "\t\tfor name in names:\n",
    "\t\t\tfilename.write(\"%s\\t%s\\n\" % (name, \"\\t\".join(map(decimal2, \n",
    "\t                         [ranks[method][name] for method in methods]))))\n",
    "\n",
    "\n",
    "# num of feature use this\n",
    "f1,f2 = change_file_re(filepath_arp_set,filepath_icmp_set)\n",
    "X,Y = pre_fe_la(f1,f2,1)\n",
    "\n",
    "print \"rf.........\"\n",
    "RF(X,Y)\n",
    "\n",
    "choice_file_re(filepath_arp_set,filepath_icmp_set)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x = np.array(readfile_set(filepath_icmp_set))\n",
    "# draw_kde_icmp_single(readfile_set(filepath_icmp_set)[0])\n",
    "# draw_sort(readfile_sort_set(filepath_icmp_set)[0])\n",
    "\n",
    "#print readfile_set(filepath_icmp_set)[2]\n",
    "# draw_kde_icmp_single(readfile_set(filepath_arp_set)[2])\n",
    "# draw_kde_icmp_single(readfile_set(filepath_icmp_set)[0])\n",
    "# draw_single(readfile_set(filepath_arp_set)[1])\n",
    "\n",
    "\n",
    "#draw_single(readfile_set(filepath_icmp_set)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], 3, [4, 5, 6, 7], 8]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =[[[1,2],3] ,[[4,5,6,7],8],[[9,10,11],12]]\n",
    "b = []\n",
    "a[1][0] + a[2][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
